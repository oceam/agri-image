{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oceam/agri-image/blob/main/codes/Calculate_cc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t00b7SyrPGa7"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oceam/agri-image/blob/main/codes/Calculate_cc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYbMyBfrbso_"
      },
      "source": [
        "# Image segmentation use Machine learning\n",
        "\n",
        "> 画像分割\n",
        "\n",
        "# Calculate the Plant Canopy Cover\n",
        "\n",
        "> 植物植被率の算出\n",
        "\n",
        "Haozhou Wang & Wei Guo  \n",
        "2022.11.21-> 2023.08.31"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XffKNjyb8I7T"
      },
      "source": [
        "# Hidden Codes\n",
        "\n",
        "> 隠しコード\n",
        "\n",
        "All the codes used in this course are hidden here, you can use `course.xxxx()` to run some functions\n",
        "\n",
        "> このコースで使用されるすべてのコードはここに隠されています。いくつかの関数を実行するために `course.xxxx()` を使用することができます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0gUtOm7zXOB"
      },
      "outputs": [],
      "source": [
        "# import packages\n",
        "from google.colab import files\n",
        "\n",
        "import os\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from skimage.io import imread"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5-j5rVX7eLK"
      },
      "outputs": [],
      "source": [
        "from skimage.filters import threshold_otsu\n",
        "from skimage import morphology\n",
        "\n",
        "import time\n",
        "import sys\n",
        "from matplotlib.colors import ListedColormap\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from skimage import io, color\n",
        "\n",
        "class Course:\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    ##################\n",
        "    # 3 index values #\n",
        "    ##################\n",
        "    @staticmethod\n",
        "    def ExG(img_np):\n",
        "        img = img_np.astype(np.float32)\n",
        "        R = img[:, :, 0]\n",
        "        G = img[:, :, 1]\n",
        "        B = img[:, :, 2]\n",
        "\n",
        "        return 2 * G - R - B\n",
        "\n",
        "    @staticmethod\n",
        "    def ExR(img_np):\n",
        "        img = img_np.astype(np.float32)\n",
        "        R = img[:, :, 0]\n",
        "        G = img[:, :, 1]\n",
        "        B = img[:, :, 2]\n",
        "\n",
        "        return 1.4 * R - G\n",
        "\n",
        "    @staticmethod\n",
        "    def NDI(img_np):\n",
        "        img = img_np.astype(np.float32)\n",
        "        R = img[:, :, 0]\n",
        "        G = img[:, :, 1]\n",
        "        B = img[:, :, 2]\n",
        "\n",
        "        return (G - R) / (G + R + 0.0000000001)  # solve G=0 and R=0\n",
        "\n",
        "\n",
        "    #########################\n",
        "    # Otsu Threshold method #\n",
        "    #########################\n",
        "    @staticmethod\n",
        "    def otsu(image):\n",
        "        thresh = threshold_otsu(image)\n",
        "        return image > thresh\n",
        "\n",
        "    ######################\n",
        "    # Calculate coverage #\n",
        "    ######################\n",
        "    @staticmethod\n",
        "    def coverage(binary_img):\n",
        "        h, w = binary_img.shape\n",
        "        total = h * w\n",
        "\n",
        "        true_num = np.sum(binary_img==True)\n",
        "\n",
        "        return true_num / total\n",
        "\n",
        "    @staticmethod\n",
        "    def plant_index_otsu(img_list, figsize=None, dpi=300):\n",
        "        img_num = len(img_list)\n",
        "        if figsize is None:\n",
        "            figsize = (4*img_num, 9)\n",
        "        fig, ax = plt.subplots(3, img_num, figsize=figsize, dpi=300)\n",
        "\n",
        "        if img_num == 1:\n",
        "            ax = ax.reshape(3, 1)\n",
        "\n",
        "        for i, test_img in enumerate(img_list):\n",
        "            exg1 = course.ExG(test_img)\n",
        "            exr1 = course.ExR(test_img)\n",
        "\n",
        "            ex_GR1 = exg1 - exr1\n",
        "\n",
        "            exg1_otsu = course.otsu(exg1)\n",
        "\n",
        "            binary_GR1 = ex_GR1 > 0\n",
        "\n",
        "\n",
        "            ax[0,i].set_title(f\"Image {i+1}\")\n",
        "\n",
        "            ax[0,i].imshow(test_img)\n",
        "            ax[0,i].set_xticks([])\n",
        "            ax[0,i].set_yticks([])\n",
        "            ax[0,i].set_xticklabels([])\n",
        "            ax[0,i].set_yticklabels([])\n",
        "\n",
        "            ax[1,i].set_title(f\"{round(course.coverage(exg1_otsu)*100, 2)}%\")\n",
        "            ax[1,i].imshow(exg1_otsu, cmap=\"gray\")\n",
        "            ax[1,i].set_xticks([])\n",
        "            ax[1,i].set_yticks([])\n",
        "            ax[1,i].set_xticklabels([])\n",
        "            ax[1,i].set_yticklabels([])\n",
        "            ax[1,i].set_xlabel(f\"ExG + Otsu\")\n",
        "\n",
        "            ax[2,i].set_title(f\"{round(course.coverage(binary_GR1)*100, 2)}%\")\n",
        "            ax[2,i].imshow(binary_GR1, cmap=\"gray\")\n",
        "            ax[2,i].set_xlabel(f\"ExG-ExR>0\")\n",
        "            ax[2,i].set_xticks([])\n",
        "            ax[2,i].set_yticks([])\n",
        "            ax[2,i].set_xticklabels([])\n",
        "            ax[2,i].set_yticklabels([])\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    ########################\n",
        "    # Supervised ML by CSV #\n",
        "    ########################\n",
        "    @staticmethod\n",
        "    def expand_colorspace(img):\n",
        "        # img is the ndarray from io.imread()\n",
        "        (h, w, dimen) = img.shape\n",
        "\n",
        "        if dimen == 4: # exist alpha layer (RGBA)\n",
        "            img = img[:,:, 0:3]\n",
        "            dimen = 3\n",
        "\n",
        "        rgb = img.reshape(h * w, dimen)\n",
        "        lab = color.rgb2lab(img).reshape(h * w, dimen)\n",
        "        hsv = color.rgb2hsv(img).reshape(h * w, dimen)\n",
        "\n",
        "        exp_img = np.concatenate((rgb, lab, hsv), axis=1)\n",
        "\n",
        "        return exp_img\n",
        "\n",
        "    @staticmethod\n",
        "    def training_data_from_easypcc_csv(csv_path, crop_name='Crop'):\n",
        "        csv_data = pd.read_csv(csv_path)\n",
        "        px_num = len(csv_data)\n",
        "\n",
        "        # convert R G B vertical list to skimage.color.pixels\n",
        "        csv_rgb = np.stack([csv_data[['R']], csv_data[['G']], csv_data[['B']]], axis=2)\n",
        "        # convert in python way, incase JS not get same results\n",
        "        lab = color.rgb2lab(csv_rgb).reshape(px_num, 3)\n",
        "        hsv = color.rgb2hsv(csv_rgb).reshape(px_num, 3)\n",
        "        # merge to list\n",
        "        train_data = np.concatenate((csv_data[['R', 'G', 'B']], lab, hsv), axis=1)\n",
        "\n",
        "        train_kind = np.zeros((px_num, 1))\n",
        "        train_kind[csv_data['Class'] == crop_name, :] = 1\n",
        "\n",
        "        return train_data, train_kind\n",
        "\n",
        "    @staticmethod\n",
        "    def train_model(train_data, train_kind, classifier=\"CART\"):\n",
        "        # classifier = [\"CART\", \"SVM\", \"RF\"]\n",
        "        t0 = time.time()\n",
        "        if classifier == \"CART\":\n",
        "            clf = DecisionTreeClassifier(max_depth=20)\n",
        "        elif classifier == \"SVM\":\n",
        "            clf = LinearSVC()\n",
        "        elif classifier == \"RF\":\n",
        "            clf = RandomForestClassifier()\n",
        "        elif classifier == \"GDBT\":\n",
        "            clf = GradientBoostingClassifier()\n",
        "\n",
        "        clf = clf.fit(train_data, train_kind)\n",
        "        t1 = time.time()\n",
        "\n",
        "        print(f'|-- Training model time cost={int(t1-t0)}s')\n",
        "        return clf\n",
        "\n",
        "    def predict_model(self, clf_img, model):\n",
        "        (h, w, dimen) = clf_img.shape\n",
        "        exp_clf_img = self.expand_colorspace(clf_img)\n",
        "        pred_result = model.predict(exp_clf_img).reshape(h, w)\n",
        "        return pred_result\n",
        "\n",
        "    def apply_model(self, clf_img, model):\n",
        "        t0 = time.time()\n",
        "        (h, w, dimen) = clf_img.shape\n",
        "        if h * w >= 1600 * 1600:  # slice picture to save RAM\n",
        "            slice_num = np.ceil(w * h / (1600 * 1600)).astype(np.int32)\n",
        "            break_points = np.linspace(0, h, num=slice_num).astype(np.int32)\n",
        "            line_st = break_points[:-1]\n",
        "            line_ed = break_points[1:]\n",
        "        else:\n",
        "            line_st = [0]\n",
        "            line_ed = [h]\n",
        "\n",
        "        pred_result = np.empty((0, w))\n",
        "        i = 0\n",
        "        for st, ed in zip(line_st, line_ed):\n",
        "            clf_result = self.predict_model(clf_img[st:ed, :], model)\n",
        "            pred_result = np.vstack((pred_result, clf_result))\n",
        "\n",
        "            percent = round((i+1) / len(line_st) * 100, 2)\n",
        "            print('\\r|' + '='*round(percent/2) + '>'+ ' '*round(50-percent/2) + '|' + str(percent) + '%', end=\"\")\n",
        "            i += 1\n",
        "        t1 = time.time()\n",
        "        print(f'| Cost={int(t1-t0)}s')\n",
        "        return pred_result\n",
        "\n",
        "    @staticmethod\n",
        "    def save_result(pred_result, img_save_name, color_list):\n",
        "        color_list = np.array(color_list)/255\n",
        "        cmap_cf = ListedColormap(color_list, name='colorfriendly')\n",
        "        plt.imsave(img_save_name, pred_result, cmap=cmap_cf)\n",
        "\n",
        "    @staticmethod\n",
        "    def denoise(image, min_obj_size=100, area_thresh=25):\n",
        "        cleaned1 = morphology.remove_small_objects(image==1, min_size=min_obj_size)\n",
        "        cleaned1 = morphology.remove_small_holes(cleaned1, area_threshold=area_thresh)\n",
        "\n",
        "        return cleaned1\n",
        "\n",
        "    ###############\n",
        "    # SML wrapper #\n",
        "    ###############\n",
        "    def supervise_machine_learning(self, uav_image, uav_train, denoise=\"default\", save=None):\n",
        "        test1 = imread(uav_image)\n",
        "        train_data, train_kind = self.training_data_from_easypcc_csv(uav_train)\n",
        "        model = self.train_model(train_data, train_kind, classifier=\"CART\")\n",
        "        result = self.apply_model(test1, model)\n",
        "        if denoise == \"default\":\n",
        "            result_clean = self.denoise(result)\n",
        "        else:\n",
        "            result_clean = self.denoise(result, denoise[0], denoise[1])\n",
        "\n",
        "        fig, ax = plt.subplots(1, 3, figsize=(6,9), dpi=300)\n",
        "        ax[0].imshow(test1)\n",
        "        ax[0].set_xticks([])\n",
        "        ax[0].set_yticks([])\n",
        "        ax[0].set_xticklabels([])\n",
        "        ax[0].set_yticklabels([])\n",
        "        ax[0].set_xlabel(\"Original Image\")\n",
        "\n",
        "        ax[1].set_title(f\"{round(self.coverage(result)*100, 2)}%\")\n",
        "        ax[1].imshow(result, cmap=\"gray\")\n",
        "        ax[1].set_xticks([])\n",
        "        ax[1].set_yticks([])\n",
        "        ax[1].set_xticklabels([])\n",
        "        ax[1].set_yticklabels([])\n",
        "        ax[1].set_xlabel(\"Classified by ML\")\n",
        "\n",
        "        ax[2].set_title(f\"{round(self.coverage(result_clean)*100, 2)}%\")\n",
        "        ax[2].imshow(result_clean, cmap=\"gray\")\n",
        "        ax[2].set_xticks([])\n",
        "        ax[2].set_yticks([])\n",
        "        ax[2].set_xticklabels([])\n",
        "        ax[2].set_yticklabels([])\n",
        "        ax[2].set_xlabel(\"Denoised\")\n",
        "        if save is not None:\n",
        "            os.makedirs(save, exist_ok=True)\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(f\"{save}/result_{uav_image.split('/')[-1]}\")\n",
        "            plt.close()\n",
        "        else:\n",
        "            plt.show()\n",
        "\n",
        "        return round(self.coverage(result)*100, 2), round(self.coverage(result_clean)*100, 2)\n",
        "\n",
        "\n",
        "course = Course()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZHCgeuEYk_0"
      },
      "source": [
        "# Section 0: Data Preparation\n",
        "\n",
        "> 第0項 データの準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqBna6301W8W"
      },
      "source": [
        "Download dataset from google drive link:\n",
        "\n",
        "> データセットをgoogle driveのリンクからダウンロードする。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-Kkx9kRga9I"
      },
      "outputs": [],
      "source": [
        "# download file from google drive\n",
        "# file link: https://drive.google.com/file/d/1rlMmWCpSsZ94-t50IRM6iwvuIdF6e-Ak/view\n",
        "# download link(when you click download): https://drive.google.com/u/1/uc?id=1rlMmWCpSsZ94-t50IRM6iwvuIdF6e-Ak&export=download\n",
        "# use id from download link\n",
        "!gdown --id 1rlMmWCpSsZ94-t50IRM6iwvuIdF6e-Ak"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37ToLA38qFQq"
      },
      "source": [
        "Then unzip that example data by:\n",
        "\n",
        "> そして、その例のデータをbyで解凍してください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDAp5RLPwo_V"
      },
      "outputs": [],
      "source": [
        "!unzip ccexample.zip  # change the example.zip to any other zip file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8G_WX_Bx6pU"
      },
      "source": [
        "Here is the all images used in this course (UAV flight at 15m)\n",
        "\n",
        "> 本講座で使用した全画像はこちら（15mでのUAV飛行）。\n",
        "\n",
        "![](https://www.dropbox.com/s/e2ubk1sezraa2o7/ccexample.png?dl=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2drOE0Aynbj"
      },
      "source": [
        "# Section 1: Background\n",
        "\n",
        "> 第1章：背景\n",
        "\n",
        "How to estimate plant coverage from images\n",
        "\n",
        "> 画像から植物被覆率を推定する方法"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0Sy7ubCrtHm"
      },
      "source": [
        "Images are consisted by large amount of pixels:\n",
        "\n",
        "> 画像は大量の画素で構成されています。\n",
        "\n",
        "![](https://www.dropbox.com/s/v83fxxgaeh6cigi/colab_20210629163507.gif?dl=1)\n",
        "\n",
        "If we can judge each pixel whether a plant pixel or soil pixel\n",
        "\n",
        "> 各画素が植物の画素か土壌の画素かを判断することができれば\n",
        "\n",
        "$$ \\frac{\\text{number of plants}}{\\text{number of all pixels}} = \\frac{\\text{plant area}}{\\text{full area}} = \\text{plant coverage}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZDq7uI7tY7W"
      },
      "source": [
        "### How can we judge pixel classes?\n",
        "\n",
        "> 画素クラスはどのように判断すればよいのでしょうか。\n",
        "\n",
        "One way is judge one by one manually (Paint to different pure colors for easier identify).\n",
        "\n",
        "> 1つ1つ手作業で判定する方法もあります（識別しやすいように異なる純色に塗る）。\n",
        "\n",
        "![](https://www.dropbox.com/s/xmvjd8wn6ij4gw5/colab_20210629164607.gif?dl=1)\n",
        "\n",
        "\n",
        "It is a necessary step when prepare \"ground truth\" for computer vision experiments\n",
        "\n",
        "> コンピュータビジョンの実験に必要な「グランドトゥルース」を準備する際に必要なステップです。\n",
        "\n",
        "---\n",
        "\n",
        "But previous is very tedious, do we have any automatic way?\n",
        "\n",
        "> でも、前回はとても面倒なので、自動でできる方法はないでしょうか？\n",
        "\n",
        "The answer is true, because in computer, the colors is actually a group of numbers\n",
        "\n",
        "> コンピュータでは、色は実際には数字の集まりですから、答えは正しいのです\n",
        "\n",
        "![](https://www.dropbox.com/s/yxsz9h31j5fnhjg/colab_20210629164956.png?dl=1)\n",
        "\n",
        "We can use three-primary colours (red, green, and blue) and its intensity to represent all kinds of visuable colors.\n",
        "\n",
        "> 赤、緑、青の3原色とその強度を用いて、目に見えるあらゆる色を表現することができるのです。\n",
        "\n",
        "For example, we have a image like this:\n",
        "\n",
        "> 例えば、こんな画像があります。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pd_wx1lbzDSS"
      },
      "outputs": [],
      "source": [
        "# read images into code\n",
        "paper = imread('ccexample/imgs/paper.png')\n",
        "paper = paper[:, :, 0:3]\n",
        "\n",
        "# display image\n",
        "plt.imshow(paper)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgJz9acF0odO"
      },
      "source": [
        "what is actually saved in the computer?\n",
        "\n",
        "> 実際にパソコンに保存されているものは何ですか？"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2bOhOQw0vZD"
      },
      "outputs": [],
      "source": [
        "paper.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wF8E8lBK06Gb"
      },
      "source": [
        "The `.shape` tells the size of this image, it is 844 pixel height, 1218 pixel width, and 3 channels with RGB.\n",
        "\n",
        "> `.shape`はこの画像の大きさを示しており、縦844ピクセル、横1218ピクセル、RGBの3チャンネルとなっています。\n",
        "\n",
        "Here is the code to check the values of the left upper corner pixel:\n",
        "\n",
        "> 以下は、左上隅のピクセルの値をチェックするコードです。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMEHwLtp0n8e"
      },
      "outputs": [],
      "source": [
        "paper[0,0,:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzD7kvhs1eWQ"
      },
      "source": [
        "It means, Red=255, Green=255, and Blue=254.\n",
        "\n",
        "> つまり、赤＝255、緑＝255、青＝254ということです。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RPKkIi4wML_"
      },
      "source": [
        "# Section 2: Classify by simple values\n",
        "\n",
        "> 第2項 単純な値で分類する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZCXf_-xyZ4O"
      },
      "source": [
        "### Classify by a single color channel\n",
        "\n",
        "> 単一カラーチャンネルによる分類\n",
        "\n",
        "In the following figure, we can see the leaves are green and background are yellow\n",
        "\n",
        "> 次の図では、葉が緑、背景が黄色であることがわかります。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HeHy_zsP2B9L"
      },
      "outputs": [],
      "source": [
        "plt.imshow(paper)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYlofVfn0Z5v"
      },
      "source": [
        "And according to this color table, we can see the yellow color both have very high R & G values, but the green color have low R and hight G values.\n",
        "\n",
        "> そして、このカラーテーブルによると、黄色は両方ともRとGの値が非常に高いが、緑色はRが低く、Gの値が高いことがわかる。\n",
        "\n",
        "![](https://www.dropbox.com/s/ntkgooo8uj55g0u/colab_20210629171807.png?dl=1)\n",
        "\n",
        "So we can define a threshold, to say all R values < 100 are green leaves, otherwise is background\n",
        "\n",
        "> そこで、R値が100未満のものは緑の葉、それ以外は背景とする閾値を定義することができる。\n",
        "\n",
        "The following code `paper[:,:,0]` means: choose all height (the first `:`), and all width (the second `:`), and only the first layer (The third `0`) in color channel (red color)\n",
        "\n",
        "> 次のコード `paper[:,:,0]` は、高さ (最初の `:`) と幅 (2番目の `:`) をすべて選択し、最初のレイヤー (3番目の `0`) のみをカラーチャンネル (赤色) で表示することを意味します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akSrHb4Eo9Do"
      },
      "outputs": [],
      "source": [
        "plt.imshow(paper[:,:,0] < 100, cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsozyJRV3dn-"
      },
      "source": [
        "The white color indicate the pixels R values < 100.\n",
        "\n",
        "> 白色はR値＜100の画素を示す。\n",
        "\n",
        "But it seems bad result.\n",
        "\n",
        "> しかし、結果は芳しくないようです。\n",
        "\n",
        "Because the color interactions are very complecated, using simple green channel can not distinuish very well.\n",
        "\n",
        "> 色の相互作用は非常に複雑であるため、単純なグリーンチャンネルを使用してもあまり区別することができません。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uZryPo_9iRX"
      },
      "source": [
        "### Classify by color index values\n",
        "\n",
        "> カラーインデックス値で分類する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tayANPHY4W_l"
      },
      "source": [
        "In the paper of \"[Verification of color vegetation indices for automated crop imaging applications](https://doi.org/10.1016/j.compag.2008.03.009)\n",
        "\", Meyer proposed three index calculated from RGB values: `NDI`, `ExG`, and `ExR`\n",
        "\n",
        "> \"[自動作物画像処理アプリケーションのためのカラー植生指標の検証](https://doi.org/10.1016/j.compag.2008.03.009)\"の論文で、Meyerは、RGB値から計算される3つのインデックスを提案した。`NDI`, `ExG`, `ExR`です。\n",
        "\n",
        "![](https://www.dropbox.com/s/4dyiju0vg0bnmkz/colab_20210629173055.png?dl=1)\n",
        "\n",
        "By using three values, it strength the differences between leaves and backgrounds.\n",
        "\n",
        "> 3つの値を使うことで、葉と背景の違いを強調しています。\n",
        "\n",
        "Meanwhile, instead of manual given a value (e.g. 100 in previous cases, it used an automatic method: Otsu Threshold)\n",
        "\n",
        "> 一方、手動で値を与えるのではなく（例：従来は100）、自動的な方法：大津式閾値を使用した\n",
        "\n",
        "<p><a href=\"https://commons.wikimedia.org/wiki/File:Otsu%27s_Method_Visualization.gif#/media/File:Otsu's_Method_Visualization.gif\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/3/34/Otsu%27s_Method_Visualization.gif\" alt=\"Otsu's Method Visualization.gif\"></a></p>\n",
        "\n",
        "Let us recurrent this experiment:\n",
        "\n",
        "> この実験を再現してみましょう。\n",
        "\n",
        "**Show the strength results like paper**\n",
        "\n",
        "> 強度結果を紙のように表示する\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4r6a2Cz6eYu"
      },
      "outputs": [],
      "source": [
        "exg_p = course.ExG(paper)\n",
        "exr_p = course.ExR(paper)\n",
        "ndi_p = course.NDI(paper)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUa7rtX58ek_"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 3, figsize=(9, 3), dpi=300)\n",
        "\n",
        "ax[0].set_title(\"NDI Tonal Image\")\n",
        "ax[0].imshow(ndi_p, cmap=\"gray\")\n",
        "\n",
        "ax[1].set_title(\"ExG Tonal Image\")\n",
        "ax[1].imshow(exg_p, cmap=\"gray\")\n",
        "\n",
        "ax[2].set_title(\"ExR Tonal Image\")\n",
        "ax[2].imshow(exr_p, cmap=\"gray\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_r1nMPz8wxd"
      },
      "source": [
        "**Change to a black and white 2 class figure**\n",
        "\n",
        "> 白黒2クラスフィギュアへの変更"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7m7vkUP82_o"
      },
      "outputs": [],
      "source": [
        "ndi_p_otsu = course.otsu(ndi_p)\n",
        "exg_p_otsu = course.otsu(exg_p)\n",
        "\n",
        "ExG_ExR_p = exg_p - exr_p\n",
        "binary_GR_p = ExG_ExR_p > 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BE9LX7HE9IJt"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 3, figsize=(9, 3), dpi=300)\n",
        "\n",
        "ax[0].set_title(\"NDI+Otsu Binary Image\")\n",
        "ax[0].imshow(ndi_p_otsu, cmap=\"gray\")\n",
        "ax[0].set_xlabel(f\"{round(course.coverage(ndi_p_otsu)*100, 2)}%\")\n",
        "\n",
        "ax[1].set_title(\"ExG+Otsu Binary Image\")\n",
        "ax[1].imshow(exg_p_otsu, cmap=\"gray\")\n",
        "ax[1].set_xlabel(f\"{round(course.coverage(exg_p_otsu)*100, 2)}%\")\n",
        "\n",
        "ax[2].set_title(\"ExG-ExR Binary Image\")\n",
        "ax[2].imshow(binary_GR_p, cmap=\"gray\")\n",
        "ax[2].set_xlabel(f\"{round(course.coverage(binary_GR_p)*100, 2)}%\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AC6YbsQK9z33"
      },
      "source": [
        "### Practice on simple paddy practices\n",
        "\n",
        "> 水田の実践"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZXSztbh-GcF"
      },
      "source": [
        "Here we have two paddy images\n",
        "\n",
        "> ここでは、2つの水田を撮影しています。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_F1XAEe9y4v"
      },
      "outputs": [],
      "source": [
        "# read paddy data\n",
        "test1 = imread('ccexample/imgs/test1.jpg')\n",
        "test2 = imread('ccexample/imgs/test2.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "loiBamPf-5fQ"
      },
      "outputs": [],
      "source": [
        "course.plant_index_otsu([test1, test2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fH_xvzYoAp3t"
      },
      "source": [
        "### Test on UAV image\n",
        "\n",
        "> UAV画像でのテスト"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwrK9RyHAtEB"
      },
      "source": [
        "Please use the following code, upload two UAV images into Colab:\n",
        "\n",
        "> 以下のコードを使用して、2つのUAV画像をColabにアップロードしてください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTIxkp2pA1Co"
      },
      "outputs": [],
      "source": [
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1L3eBfHsA5WI"
      },
      "source": [
        "Then change the file name in the follwoing code by two images just uploaded:\n",
        "\n",
        "> 次に、以下のコードのファイル名を、先ほどアップロードした2つの画像に変更します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JraJeEejA-3T"
      },
      "outputs": [],
      "source": [
        "your_uav1 = imread('200421_11_DJI_0402.JPG')   # <- change the string here for image one\n",
        "your_uav2 = imread('200422_11_DJI_0206.JPG')   # <- change the string here for image two"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVTxxQWHBJrm"
      },
      "source": [
        "Run the following code to see the results!\n",
        "\n",
        "> 次のコードを実行して、結果を確認してください"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4BiwOcdIBJFl"
      },
      "outputs": [],
      "source": [
        "course.plant_index_otsu([your_uav1, your_uav2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gRAC11nBuw9"
      },
      "source": [
        "How is your results look like? Do they performs perfectly?\n",
        "\n",
        "> 結果はどのように見えますか？完璧に動作していますか？\n",
        "\n",
        "Don't worry if your results are not perfect, we have solutions for dealing with some complex images.\n",
        "\n",
        "> 複雑な画像を扱うためのソリューションも用意していますので、結果が完璧でない場合もご安心ください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZHZzKOrDosT"
      },
      "source": [
        "### Problems when dealing with complex background\n",
        "\n",
        "> 複雑な背景を扱う場合の問題点"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcVnEoNeDvd0"
      },
      "source": [
        "Let us test on our broccoli data\n",
        "\n",
        "> ブロッコリーのデータでテストしてみましょう"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7WAdi8X4GC_1"
      },
      "outputs": [],
      "source": [
        "broccoli1 = imread(\"ccexample/broccoli/200421_11_DJI_0402.JPG\")\n",
        "broccoli2 = imread(\"ccexample/broccoli/200430_11_DJI_0413.JPG\")\n",
        "broccoli3 = imread(\"ccexample/broccoli/200508_11_DJI_0400.JPG\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQ8tLep9D_8w"
      },
      "outputs": [],
      "source": [
        "course.plant_index_otsu([broccoli1, broccoli2, broccoli3], figsize=(6,7))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPB64eKzJihJ"
      },
      "source": [
        "The broccoli part seems acceptable, but the some weeds are also distinguished as the plant part, what if we do not want those weeds be counted in?\n",
        "\n",
        "> ブロッコリーの部分は問題なさそうですが、雑草も植物部分として区別されているので、その雑草はカウントしないでほしいという場合はどうすればいいのでしょうか？"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXeBZTZLAgAW"
      },
      "source": [
        "# Section 3: Classify by supervised machine learning\n",
        "\n",
        "> 第3項 教師付き機械学習による分類"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIJHQd6PCq-A"
      },
      "source": [
        "The supervised machine learning means\n",
        "\n",
        "> 教師あり機械学習とは\n",
        "\n",
        "Human prepare the some examples to machine, the machine itself will try to learn the regulation behind the examples that you give.\n",
        "\n",
        "> 人間がいくつかの例を用意すると、機械はその例の背後にある規則を学習しようとします。\n",
        "\n",
        "Here is the main steps for classifying images:\n",
        "\n",
        "> ここでは、画像を分類するための主な手順を説明します。\n",
        "\n",
        "1. Manual draw some parts of foreground (plants) and backgrounds (sold and weeds)  \n",
        "    > 前景（植物）と背景（売られているもの、雑草）の一部を手動で描画する。    \n",
        "\n",
        "    *Use `collectTrainJS_v2` tool in the folder*   \n",
        "    > *フォルダ内の `collectTrainJS_v2` ツールを使用*。\n",
        "1. Use those data to train models\n",
        "    > これらのデータを使ってモデルを学習させる\n",
        "1. Apply the trained models to images\n",
        "    > 学習したモデルを画像に適用する\n",
        "1. Denoise\n",
        "    > ノイズ除去\n",
        "1. Calculate the coverage\n",
        "    > カバレッジを計算する\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAFeSrUKMPLL"
      },
      "source": [
        "### Step 1: Draw training data (examples for machine) by `collectTrainJS_v2`\n",
        "\n",
        "> Step 1: `collectTrainJS_v2` により学習データ (機械学習用の例) を作成する。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azm6umdzMd9h"
      },
      "source": [
        "You can using the following tool, to prepare the foreground and background training data.\n",
        "\n",
        "> フォアグラウンドとバックグラウンドの学習データを準備するために、以下のツールを使用することができます。\n",
        "\n",
        "1. Download the image file to your local machine\n",
        "\n",
        "    > イメージファイルをローカルマシンにダウンロードする  \n",
        "\n",
        "    <img src=\"https://drive.google.com/uc?id=1tGH85g7U0UqwNu4XR9GzohIDvCaTAR3e\" alt=\"Google Drive Image\" />\n",
        "\n",
        "2. Run the following code, and drop the downloaded image file:\n",
        "\n",
        "    > 以下のコードを実行し、ダウンロードした画像ファイルをドロップしてください。\n",
        "\n",
        "    <img src=\"https://drive.google.com/uc?id=1UVscGa8MZJ4y7Q2yMPkwNrTJVzE8cMpg\" alt=\"Google Drive Image\" />\n",
        "\n",
        "\n",
        "3. Draw the foreground and background respectively\n",
        "\n",
        "   > 前景と背景をそれぞれ描画する.\n",
        "\n",
        "   <img src=\"https://drive.google.com/uc?id=1_GnmkZfdMLJGBWy3HgfihH5VSiKUv3Cw\" alt=\"Google Drive Image\" />\n",
        "\n",
        "   Examples for broccoli:    \n",
        "\n",
        "   > ブロッコリーの例   \n",
        "\n",
        "|   | example 1 | example 2|  \n",
        "|---| ---       |  ---     |  \n",
        "| foreground  | <img src=\"https://www.dropbox.com/s/5gvjsiyrmwnh0d2/colab_20210629144543.png?dl=1\" height=\"500\"/> | <img src=\"https://www.dropbox.com/s/xvbvpx448ksrbmk/colab_20210629155919.png?dl=1\" height=\"500\" />|   \n",
        "| background. | <img src=\"https://www.dropbox.com/s/2f3uzb00crozoa6/colab_20210629144750.png?dl=1\" height=\"500\"/> | <img src=\"https://www.dropbox.com/s/rd973i3vycdttec/colab_20210629160247.png?dl=1\" height=\"500\"/> |\n",
        "\n",
        "\n",
        "4. Save the result `tranData_2class.csv` to local disk, and then upload to the colab files.\n",
        "\n",
        "    > 結果 `tranData_2class.csv` をローカルディスクに保存し、colab ファイルにアップロードする。   \n",
        "\n",
        "    <img src=\"https://drive.google.com/uc?id=15vIh5U_xMWTRFX7X1tPoVuG-KV5eGe_E\" alt=\"Google Drive Image\" />\n",
        "\n",
        "    We already provide a pre-labeled file, you can use this directly, or upload your own csv file.    \n",
        "\n",
        "    >  すでにラベル付けされたファイルを提供していますので、これをそのまま使うこともできますし、ご自分のcsvファイルをアップロードすることもできます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-IXwAeIl_qF"
      },
      "outputs": [],
      "source": [
        "%%html\n",
        "<script src=\"https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js\"></script>\n",
        "<script src=\"https://cdn.jsdelivr.net/gh/oceam/agri-image/codes/easypcc_colab_js/color.js\"></script>\n",
        "<link type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/oceam/agri-image/codes/easypcc_colab_js/base.css\" rel=\"stylesheet\" />\n",
        "<script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/gh/oceam/agri-image/codes/easypcc_colab_js/filePicker.js\"></script>\n",
        "<script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/gh/oceam/agri-image/codes/easypcc_colab_js/trainingData.js\"></script>\n",
        "\n",
        "<!-- <canvas id=\"renderCanvas\" touch-action=\"none\" width=\"1280px\" height=\"720px\">\n",
        "</canvas> -->\n",
        "<h6>Rerun to refresh. Left click to drag, right click to draw, scroll to zoom, click the classes to change annotations.</h6>\n",
        "<div id=\"files\"></div>\n",
        "<div id=\"classes\"></div>\n",
        "<div id=\"canvasArea\" height=\"720px\"></div>\n",
        "<div id=\"control\"></div>\n",
        "<!-- <canvas id=\"renderCanvas\" touch-action=\"none\" width=\"1280px\" height=\"720px\" style=\"z-index=-1\"></canvas>  -->\n",
        "\n",
        "<script>\n",
        "    google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "</script>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ilh7NDs7NDhN"
      },
      "source": [
        "After drawing training data, upload the csv file to colab\n",
        "\n",
        "> 学習データを描画した後、csvファイルをcolabにアップロードする"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwTd5NGmOyH-"
      },
      "source": [
        "### Step 1.5: Load csv data into Colab\n",
        "\n",
        "> ステップ1.5：csvデータをColabに読み込む"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5NJi-MJPCDw"
      },
      "outputs": [],
      "source": [
        "train_csv = \"ccexample/broccoli/200508_11_DJI_0400.csv\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X20reRhoPU1r"
      },
      "outputs": [],
      "source": [
        "train_data, train_kind = course.training_data_from_easypcc_csv(train_csv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLgApB_PP4hR"
      },
      "source": [
        "### Step 2: train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2X_hotU9QBTS"
      },
      "outputs": [],
      "source": [
        "model = course.train_model(train_data, train_kind, classifier=\"CART\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EpSRzjNQRj1"
      },
      "source": [
        "### Step 3: apply model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6iQy2P9QKtA"
      },
      "outputs": [],
      "source": [
        "test1 = imread('ccexample/broccoli/200421_11_DJI_0402.JPG')\n",
        "plt.figure(figsize = (6,6))\n",
        "plt.imshow(test1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Auy55s5QeKJ"
      },
      "outputs": [],
      "source": [
        "result = course.apply_model(test1, model)\n",
        "plt.figure(figsize = (6,6))\n",
        "plt.imshow(result, cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4p41sIbfWxbE"
      },
      "source": [
        "### Step 4: denoise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96MUyfzVW6AX"
      },
      "outputs": [],
      "source": [
        "result_clean = course.denoise(result)\n",
        "plt.figure(figsize = (6,6))\n",
        "plt.imshow(result_clean, cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCM6FUFURxoo"
      },
      "source": [
        "### Step 4: calculate the coverage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmP4EP2MRw3u"
      },
      "outputs": [],
      "source": [
        "course.coverage(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKmlPT3qZzJu"
      },
      "outputs": [],
      "source": [
        "course.coverage(result_clean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_-mE6wdVulQ"
      },
      "source": [
        "### Step 5: merged together\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLcRNYYMVzwQ"
      },
      "outputs": [],
      "source": [
        "course.supervise_machine_learning('ccexample/broccoli/200421_11_DJI_0402.JPG', \"ccexample/broccoli/200421_11_DJI_0402.csv\", denoise=\"default\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGm3si4TSFdR"
      },
      "source": [
        "### Try your own image\n",
        "\n",
        "> 自分のイメージを試してみる"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2gd_4HESONA"
      },
      "source": [
        "First, upload your own training data\n",
        "\n",
        "> まず、自分の学習データをアップロードします"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rfNKJKkSR1u"
      },
      "outputs": [],
      "source": [
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uA-8f2NqSKrc"
      },
      "outputs": [],
      "source": [
        "uav_image = \"path/your_uav_image.jpg\"   # <- change the string here for image one\n",
        "uav_train = \"path/your_uav_train.csv\"  # <- change the string here for image one"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uav_image = \"200421_11_DJI_0402.JPG\"   # <- change the string here for image one\n",
        "uav_train = \"trainData_2classes (5).csv\"  # <- change the string here for image one"
      ],
      "metadata": {
        "id": "S4BdDLw5TQUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRyQAssuSgUR"
      },
      "outputs": [],
      "source": [
        "course.supervise_machine_learning(uav_image, uav_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6Sft9DzWXWb"
      },
      "source": [
        "# Section 4: Broccoli coverage tracking through growth\n",
        "\n",
        "> 第4章: ブロッコリーの成長過程を確認する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNv9BBRf5Lyj"
      },
      "source": [
        "Retrieve target images and their corresponding annotations, and sort them by the UAV flight date\n",
        "\n",
        "> ターゲット画像とそれに対応するアノテーションを取得し、UAVの飛行日順にソートする。\n",
        "\n",
        "\n",
        "**Important**\n",
        "\n",
        "Please rename all the images in the given folder like:\n",
        "\n",
        "> 指定されたフォルダ内の画像をすべて次のようにリネームしてください。\n",
        "\n",
        "* 200318_xxxx.JPG\n",
        "* 200345_xxxx.JPG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_pGecmQpEiV"
      },
      "outputs": [],
      "source": [
        "folder_name = \"ccexample/broccoli\"\n",
        "img_suffix = \".JPG\"\n",
        "save_path = \"'broccoli_results\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZWib9X4phy-"
      },
      "outputs": [],
      "source": [
        "entry_list = [entry for entry in os.scandir(folder_name) if entry.name.endswith(img_suffix)]\n",
        "# sort list by flight date\n",
        "entry_list = sorted(entry_list,key=lambda x:x.name.split('_')[0])\n",
        "\n",
        "converages = []\n",
        "clean_converages = []\n",
        "for entry in tqdm(entry_list, total=len(entry_list)):\n",
        "    uav_image = entry.path\n",
        "    uav_train = entry.path.replace('.JPG', '.csv')\n",
        "    converage, clean_converage = course.supervise_machine_learning(uav_image, uav_train, save=save_path)\n",
        "    converages.append(converage)\n",
        "    clean_converages.append(clean_converage)\n",
        "\n",
        "# save to csv fle\n",
        "df = {'img_name': [entry.name for entry in entry_list], 'img_path': [entry.path for entry in entry_list], 'result_path':[f'{save_path}/result_{entry.name}' for entry in entry_list], 'converages': converages, 'clean_converages': clean_converages}\n",
        "df = pd.DataFrame(df)\n",
        "df.to_csv(f'{save_path}/results.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6FUad1x6RMD"
      },
      "source": [
        "Visuazlizing broccoli coverage tracking through growth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBQ6oXJyp69P"
      },
      "outputs": [],
      "source": [
        "legendict={'size': 30, 'weight':'bold'}\n",
        "label_font = {'size': 40, 'weight':'bold'}\n",
        "linewidth = 8\n",
        "markersize = 30\n",
        "size = 30\n",
        "\n",
        "sns.set_theme(style=\"white\")\n",
        "palette = sns.color_palette()\n",
        "\n",
        "fig = plt.figure(figsize=(15,10))\n",
        "\n",
        "ax = fig.add_subplot(111)\n",
        "\n",
        "x = np.arange(len(entry_list))\n",
        "labels = [entry.name.split('_')[0] for entry in entry_list]\n",
        "\n",
        "ax.plot(x, converages, marker='o', label='converages', linewidth=linewidth,markersize=markersize, color=palette[0])\n",
        "ax.plot(x, clean_converages, marker='.', label='clean_converages', linewidth=linewidth,markersize=markersize, color=palette[1])\n",
        "\n",
        "plt.xticks(x, labels=labels, size=size, rotation=-30)\n",
        "plt.yticks(size=size)\n",
        "plt.xlabel(\"Flight date\", fontdict=label_font)\n",
        "plt.ylabel(\"Converage Rate (%)\", fontdict=label_font)\n",
        "plt.legend(prop=legendict)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "XffKNjyb8I7T"
      ],
      "name": "Calculate_cc.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}