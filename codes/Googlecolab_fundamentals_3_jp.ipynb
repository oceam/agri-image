{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oceam/agri-image/blob/main/codes/Googlecolab_fundamentals_3_jp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Googlecolab_fundamentals_3  \n",
        "Wei Guo  \n",
        "2022.08.26"
      ],
      "metadata": {
        "id": "UCW9TjRUhACA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Read and Display**\n",
        "Read an image into the memory, using the imread command. The example reads one of the most widely used standard test images in image processing, an image of a young girl in a file named lena_std.tif, and stores it in an array named I .  Read the story of [Lena here](http://www.lenna.org/).   \n",
        "imreadコマンドを使用して、画像をメモリーに読み込みます。この例では、画像処理で最も広く使われている標準的なテスト画像の1つである、 lena_std.tifを読み込み、I という配列に格納しています。 Lenaの[ストーリーはこちら](http://www.lenna.org/)。\n",
        "\n"
      ],
      "metadata": {
        "id": "_ikYcQCphNte"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we learnt from last lecture, we need to import some needed libraries first.  \n",
        "前回の講義で学んだように、まず必要なライブラリをインポートする必要があります。"
      ],
      "metadata": {
        "id": "1PPxpyslQxsQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2 \n",
        "from google.colab.patches import cv2_imshow # for image display\n",
        "from skimage import io\n",
        "from PIL import Image \n",
        "import matplotlib.pylab as plt"
      ],
      "metadata": {
        "id": "fWFU48dbBaNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Digital image fundamental\n",
        "code of this section inspired by this interesting [Tutorial](https://blog.paperspace.com/the-concept-of-images-in-image-processing/)\n"
      ],
      "metadata": {
        "id": "_t4Sr1RKKqEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  creating (9, 9) array of zeros\n",
        "image = np.zeros((9, 9))\n",
        "#  attempting to visualize array\n",
        "plt.imshow(image, cmap='gray')"
      ],
      "metadata": {
        "id": "PdiIesTJ_EDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image"
      ],
      "metadata": {
        "id": "Wbvf_AzjeJ7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  creating a 1-D array (vector) of elements ranging from 0 to 80\n",
        "image = np.arange(81)\n",
        "#  reshaping vector into 2-D array\n",
        "image = image.reshape((9, 9))\n",
        "#  attempting to visualize array\n",
        "plt.imshow(image, cmap='gray')\n",
        "image"
      ],
      "metadata": {
        "id": "ZG4WQuL9FJhP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  creating the array\n",
        "image = np.zeros((9, 18)).astype(np.uint8)\n",
        "# # U\n",
        "# image[1:-3, 1] = 1\n",
        "# image[1:-3, 7] = 1\n",
        "# image[-2, 3:6] = 1\n",
        "# image[-3, 2] = 1\n",
        "# image[-3, 6] = 1\n",
        "# # T\n",
        "# image[1, 9+1:-1] = 1\n",
        "# image[1:-1, 9+4] = 1\n",
        "\n",
        "# K\n",
        "image[1:-1, 1:3] = 1\n",
        "image[4, 3] = 1\n",
        "image[3, 4] = 1\n",
        "image[2, 5] = 1\n",
        "image[1, 6] = 1\n",
        "\n",
        "image[5, 4] = 1\n",
        "image[6, 5] = 1\n",
        "image[7, 6] = 1\n",
        "\n",
        "# U\n",
        "image[1:-3, 9+1] = 1\n",
        "image[1:-3, 9+7] = 1\n",
        "image[-2, 9+3:-3] = 1\n",
        "image[-3, 9+2] = 1\n",
        "image[-3, 9+6] = 1\n",
        "plt.imshow(image,cmap='gray')"
      ],
      "metadata": {
        "id": "YHTullN6GfHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image2 = np.zeros((5, 5))\n",
        "image2[1, 0] = 1\n",
        "image2[0, 1:3] = 1\n",
        "image2[1,3] = 1\n",
        "image2[2, 2] = 1\n",
        "image2[3, 1] = 1\n",
        "image2[4, 1:4] = 1\n",
        "\n",
        "plt.imshow(image2,cmap='gray')\n"
      ],
      "metadata": {
        "id": "LhzNeB34fx6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# change to color image\n",
        "r=image*1\n",
        "g=image*255\n",
        "b=image*1\n",
        "image_color=np.dstack((r,g,b)) \n",
        "plt.imshow(image_color,cmap='gray')"
      ],
      "metadata": {
        "id": "RZV8rRIJIhc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Digital image process fundamental"
      ],
      "metadata": {
        "id": "Wog9-t5mK7Du"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now read images, and display them using openCV, please note the difference when reading image in RGB and BGR format. The default input color channels are in BGR format for openCV.  \n",
        "openCVを使って画像を読み込んで表示するわけですが，RGB形式とBGR形式で画像を読み込む場合の違いに注意してください．openCVのデフォルトの入力カラーチャンネルはBGR形式です．"
      ],
      "metadata": {
        "id": "5-i7rxVERRlb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list to store the urls of the images\n",
        "# Need to upload the image first\n",
        "I_cv = cv2.imread('lena_std.tif')  #BGR\n",
        "cv2_imshow(I_cv)\n",
        "print('\\n')\n"
      ],
      "metadata": {
        "id": "fjhJK260RgFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# or read from url directly\n",
        "url = \"http://www.lenna.org/lena_std.tif\"\n",
        "I = io.imread(url) #RGB\n",
        "cv2_imshow(I)\n",
        "print('\\n')"
      ],
      "metadata": {
        "id": "HdxBT0xKVq3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "I_cv = cv2.cvtColor(I, cv2.COLOR_RGB2BGR)\n",
        "cv2_imshow(I_cv)\n",
        "print('\\n')"
      ],
      "metadata": {
        "id": "pI8D5hsWVxMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Or can use io.imshow(I)"
      ],
      "metadata": {
        "id": "bEk9D13AgKId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "io.imshow(I)"
      ],
      "metadata": {
        "id": "1YxOhi1NgMll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "get the size of I and store it.  \n",
        "Also check Variable inspector.  \n",
        "Iのサイズを取得し、それを格納する.  \n",
        "変数インスペクタも確認."
      ],
      "metadata": {
        "id": "NkL118RpXp7w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = I_cv.shape\n",
        "print(s)\n",
        "print(I_cv.dtype)"
      ],
      "metadata": {
        "id": "sUpMJochXVDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Did the size of the array match the size of the image in pixels? Yes. You probably noticed that there was an additional value returned by the size function: 3.\n",
        "That's because the imported image is a color image, and so it needs a third dimension to store the red, green, and blue color planes.\n",
        "You can access individual color planes of an image by indexing into the third dimension. For example, you can extract the green (second) color plane using the value 2 as the third index.\n",
        "note the difference with toher language such as Matlab.  \n",
        "配列のサイズと画像のサイズ（ピクセル）は一致していましたか？はい。size関数が返す値が追加されていることにお気づきでしょうか。3.\n",
        "これは、取り込んだ画像がカラー画像であるため、赤、緑、青の色面を格納するための3次元が必要だからです。\n",
        "画像の個々の色面には、3次元へのインデックスを付けてアクセスすることができます。例えば、3番目のインデックスとして値2を使用すると、緑（2番目の）色平面を抽出することができます。\n",
        "Matlab などの他の言語との違いに注意してください。"
      ],
      "metadata": {
        "id": "3XRWHYViXztZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "B_img=I_cv[:,:,0]\n",
        "G_img=I_cv[:,:,1]\n",
        "R_img=I_cv[:,:,2]"
      ],
      "metadata": {
        "id": "Xm2ZdExSX1ya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So now you want to view multiple images. There are several different ways to do it. Let's try use syntax plt.subplots(), you define an m-by-n matrix of display regions and specify which region, p, is active.  \n",
        "さて、今度は複数の画像を表示したいと思います。そのためには、いくつかの方法があります。plt.subplots() という構文を使ってみましょう。m-by-n の表示領域の行列を定義して、どの領域 p をアクティブにするかを指定します。"
      ],
      "metadata": {
        "id": "hyukat5NbORM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplot(131).imshow(R_img, cmap = \"gray\")\n",
        "plt.subplot(132).imshow(G_img, cmap = \"gray\")\n",
        "plt.subplot(133).imshow(B_img, cmap = \"gray\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QEld2B8QbLdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Or we can use syntax hconcat(); it is similar to montage(I) in Matlab.  \n",
        "あるいは、hconcat() という構文も使えます。これは、Matlab の montage(I) に似ています。"
      ],
      "metadata": {
        "id": "qMuUQFNba6Fq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subplot_show = cv2.hconcat([R_img, G_img, B_img])\n",
        "cv2_imshow(subplot_show)\n",
        "print('\\n')"
      ],
      "metadata": {
        "id": "-AwlSGJoYq37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you just want to compare an image and a modified version of that image.\n",
        "You can display two images together by control the cv2.hconcat().  \n",
        "ある画像と，その画像を加工したものを比較したいだけならば，cv2.hconcat() を利用することができます。\n",
        "cv2.hconcat() を制御することで，2つの画像を一緒に表示することができます。"
      ],
      "metadata": {
        "id": "rsjYKY-6dYQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subplot_show = cv2.hconcat([R_img, G_img])\n",
        "cv2_imshow(subplot_show)\n",
        "print('\\n')"
      ],
      "metadata": {
        "id": "8hZCXP_cditj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most images use the unsigned 8-bit integer (uint8) data type, which stores integers from 0 to 255. Bright or brightly colored images contain pixel intensity values near 255 in one or more color planes.\n",
        "You find the largest value in an array using the max function. and the smallest value in an array using the min function.  \n",
        "ほとんどの画像は符号なし8ビット整数（uint8）データ型を使用しており、0から255までの整数を格納することができます。明るい画像や鮮やかな色の画像は、1つまたは複数の色平面で255に近い画素強度の値を含んでいます。\n",
        "配列の最大値は max 関数で、最小値は min 関数で求めます。"
      ],
      "metadata": {
        "id": "MCBOmCJJdpZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Rmax = np.max(R_img)\n",
        "print(Rmax,'\\n')\n",
        "Rmin = np.min(R_img)\n",
        "print(Rmin,'\\n')"
      ],
      "metadata": {
        "id": "EFJ8MEfXdqOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Many common tasks can be completed more quickly using functions in opencv. For example, if you want to extract all three color planes of an image array, you can use cv2.split instead of indexing into each plane individually.  \n",
        "opencv の関数を利用することで，より高速に画像処理することができます。例えば，画像配列の 3 つの色面をすべて抽出したい場合，各色面を個別にインデックス化する代わりに， cv2.split を利用することができます。"
      ],
      "metadata": {
        "id": "dLWjOJV0ejax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "B_img,G_img,R_img = cv2.split(I_cv)\n",
        "subplot_show = cv2.hconcat([R_img, G_img, B_img])\n",
        "cv2_imshow(subplot_show)\n",
        "print('\\n')"
      ],
      "metadata": {
        "id": "beWxLqRUeh1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert RGB to grayscale (check the reasons below)  \n",
        "Y = 0.299 * R + 0.587 * G + 0.114 * B\n"
      ],
      "metadata": {
        "id": "1eWpAhlDe50H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gs_img = cv2.cvtColor(I_cv, cv2.COLOR_BGR2GRAY)\n",
        "cv2_imshow(gs_img)\n",
        "sz=gs_img.shape\n",
        "print(sz)\n",
        "\n"
      ],
      "metadata": {
        "id": "Jnnsp0Cze6VS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you are analyzing a set of images, normalizing the brightness can be an important preprocessing step. \n",
        "An intensity histogram separates pixels into bins based on their intensity values. Dark images, for example, have many pixels binned in the low end of the histogram. Bright regions have pixels binned at the high end of the histogram.\n",
        "Lets assume that we have two grayscale image R_img(brighter) and G_img(darker).  \n",
        "画像を分析する場合、明るさを正規化することは重要な前処理が必要となります。\n",
        "強度ヒストグラムは、強度値に基づいてピクセルをビンに分離します。例えば、暗い画像では、多くのピクセルがヒストグラムの低域にビン詰めされています。明るい領域は、ヒストグラムの高位にビニングされたピクセルを持ちます。\n",
        "2つのグレースケール画像R_img（明るい）とG_img（暗い）があると仮定しますと以下になります。"
      ],
      "metadata": {
        "id": "Asi432Bwhgbv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(R_img.ravel(),bins = 256, range = [0,256]) \n",
        "plt.show()\n",
        "plt.hist(G_img.ravel(),bins = 256, range = [0,256]) \n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "8IMZ-CQvhhfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Increasing image contrast brightens brighter pixels and darkens darker pixels. You can use the exposure.rescale_intensity to adjust the contrast of a grayscale image automatically.  \n",
        "画像のコントラストを上げると、明るい画素は明るくなり、暗い画素は暗くなる。exposure.rescale_intensityを使えば、グレースケール画像のコントラストを自動的に調整することができます。"
      ],
      "metadata": {
        "id": "RJj6EeTkjuq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage import exposure\n",
        "R_img_Adj = exposure.rescale_intensity(R_img);\n",
        "subplot_show = cv2.hconcat([R_img, R_img_Adj])\n",
        "cv2_imshow(subplot_show)\n",
        "print('\\n')"
      ],
      "metadata": {
        "id": "0bUtyZoSlXAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "similar for RGB images"
      ],
      "metadata": {
        "id": "3EZCYzJ_nDMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p1, p99 = np.percentile(R_img, (1, 99))\n",
        "R_img_Adj = exposure.rescale_intensity(R_img, in_range=(p1, p99))\n",
        "p1, p99 = np.percentile(G_img, (1, 99))\n",
        "G_img_Adj = exposure.rescale_intensity(G_img, in_range=(p1, p99))\n",
        "p1, p99 = np.percentile(B_img, (1, 99))\n",
        "B_img_Adj = exposure.rescale_intensity(B_img, in_range=(p1, p99))\n",
        "I_Adj = np.dstack((R_img_Adj, G_img_Adj,B_img_Adj))\n",
        "\n",
        "plt.subplot(121).imshow(I)\n",
        "plt.subplot(122).imshow(I_Adj)\n",
        "plt.show()\n",
        "print('\\n')"
      ],
      "metadata": {
        "id": "WEeDhLT1nF-y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}